O passo de capturar padrões em dados é chamada de {{c1::Fitting or Training the model}} e os dados usados para <b>ajustar (fit)</b>&nbsp;os modelos são chamados de {{c2::dados de treino}}.	"<img src=""paste-5032554729d076ec87bda3969990fdf42b87cee3.jpg"">"	easy modelos
92e44c71ebd94e318aa9541053014889-ao-1		"<img src=""tmpgtat5dp3.jpg"">"	"<img src=""92e44c71ebd94e318aa9541053014889-ao-1-Q.svg"">"						"<img src=""92e44c71ebd94e318aa9541053014889-ao-1-A.svg"">"	"<img src=""92e44c71ebd94e318aa9541053014889-ao-O.svg"">"	medium
92e44c71ebd94e318aa9541053014889-ao-2		"<img src=""tmpgtat5dp3.jpg"">"	"<img src=""92e44c71ebd94e318aa9541053014889-ao-2-Q.svg"">"						"<img src=""92e44c71ebd94e318aa9541053014889-ao-2-A.svg"">"	"<img src=""92e44c71ebd94e318aa9541053014889-ao-O.svg"">"	easy
92e44c71ebd94e318aa9541053014889-ao-3		"<img src=""tmpgtat5dp3.jpg"">"	"<img src=""92e44c71ebd94e318aa9541053014889-ao-3-Q.svg"">"						"<img src=""92e44c71ebd94e318aa9541053014889-ao-3-A.svg"">"	"<img src=""92e44c71ebd94e318aa9541053014889-ao-O.svg"">"	easy
Qual a diferença entre Classification Tree e Regression Tree?	<b>Classification Tree</b> decise entre valores binários para o alvo (Sim/Não, sobreviveu/morreu, etc.)<br><br><b>Regression Tree </b>decide a partir de um valor contínuo, como o preço de uma casa.	easy modelos
Qual a base mais primordial para Data Science, pensando na Hierarquia de Necessidade em Data Science?	"Nada acontece em Data Science se não houver&nbsp;<b>dados</b>.<br><img src=""paste-6ff37ac82e6904fe9f914726c93087774faf8c65.jpg"">"	easy
Data Scientist vs Data Analyst vs Data Engineer. Citar as diferenças	"<b>Data Engineers</b> cuidam da parte de coleta de dados e armazenamento. Devem estar muito ligado na forma que está descrito os dados e como será feita a consulta deles.<br><br><b>Data Analysts</b> estão preocupados em deduzirem a interpretação dos dados apresentados. Procuram determinar as características mais importantes para o sistema. Além de prepararem os dados.<br><img src=""paste-8a681fdba424cc8e5dc47b6a5a34b3f685586ad2.jpg""><br><b>Data Scientists</b> possuem um background mais técnico do que os analysts, pois precisam também entender a utilização de cada rede e se isso se encaixaria para o problema encontrado"	medium
O que são features?	Features serão os dados ou colunas utilizadas para a predição do modelo. A partir de sua interpretação se obtém o Target.	easy
Qual a utilidade do Scikit-learn?	Com o Scikit-learn, pode-se modelar os tipos de dados associados em um dataframe.	easy
Quais são os passos para construir e usar um modelo de redes neurais?	<b>Definir</b>: consciste em explicitar qual tipo de modelo será utilizado. Além de interpretar a estrutura dos dados.<br><br><b>Treinar</b>: fazer com que o modelo encontre os padrões dentro dos dados providenciados.<br><br><b>Predict</b>: utilizar os padrões criados para predizer dados de avaliação.<br><br><b>Avaliar</b>: determinar qual a precisão e exatidão do modelo, além de diversas outras métricas.	medium
Quando o modelo combina quase que perfeitamente com os dados de treino, estamos falando do conceito de {{c1::Overfitting}}	"<img alt=""Overfitting e underfitting em Machine Learning - ABRACD - ASSOCIAÇÃO  BRASILEIRA DE CIÊNCIA DE DADOS"" src=""1_7OPgojau8hkiPUiHoGK_w.png"">"	easy
Quando o modelo falha em identificar padrões a partir das features estamos lidando com o conceito de {{c1::Underfitting}}.	"<img alt=""Overfitting e underfitting em Machine Learning - ABRACD - ASSOCIAÇÃO  BRASILEIRA DE CIÊNCIA DE DADOS"" src=""1_7OPgojau8hkiPUiHoGK_w.png"">"	easy
Uma forma de evitar overfitting e underfitting em um modelo de decision tree é decidir manualmente o número máximo de {{c1::leaves}} que o modelo poderá ter.&nbsp;&nbsp;		easy
Quais são os dois pré-requisitos para que uma Random Tree Regression Model funcione bem?<br>	<ul><li>As decision trees que compoem o modelo não podem ser correlacionadas, cada uma deve ter sua própria independência. Portanto, suas predições devem ter pouca correlação.</li><li>Deve haver sinais e padrões dentro das features escolhidas, de forma que o treino tenha melhor resultado que uma simples escolha aleatória.<br></li></ul>	easy
"Como resolver&nbsp;<img src=""paste-8d392706232010f4aef9229b1ea55affb412aa81.jpg"">"	"Por meio de uma matriz inversa&nbsp;<br><img src=""paste-356ef664cd4a1d6cd0cebfd78833bb9a7b7a5be6.jpg""><br><img src=""paste-41fc976c74b1aaf02c1ae102c8bab075a7f6b6c7.jpg""><br><br>OBS: Esse processo depende que seja possível achar A<sup>-1</sup>"	algebra_linear easy
"Qual a condição para que uma matriz A<sup>-1</sup><span style=""font-size: 20px;""><sup>&nbsp;</sup>exista?</span><sup>&nbsp;&nbsp;</sup>"	Ax = b deve ter uma solução para cada valor de b.	algebra_linear easy
Uma equação linar Ax = b terá solução, para um b&nbsp;∈ R<sup>m</sup>, caso A tenha {{c1::um número de colunas igual ou maior que m}}.	<ul><li>E a condição de n ≥ m deve existir para que a dimensionalidade do espaço de coluna seja menor que m.</li><li>Além disso, deve-se garantir que as colunas sejam linearmente independentes.</li></ul><br>	algebra_linear medium
Uma forma mais computacionalmente eficiente de calcular uma norma (distância) L<sup>2&nbsp;</sup>de um vetor é utilizando uma {{c1::norma quadrática L<sup>2</sup>, que pode ser calculada por x<sup>T</sup>x}}.		algebra_linear hard
É possível medir o tamanho de uma matrix a partir da {{c1::norma de Frobenius}}.	"<img src=""paste-5d9f04c853a0dc88d29ec9759cc664486af36197.jpg""><br><ul><li>Que é análogo a norma L<sup>2</sup> de um vetor.</li></ul>"	algebra_linear hard
Uma matriz é dita ortogonal caso se transforme em uma {{c1::matriz identidade}} caso realizarmos a operação {{c1::A<sup>T</sup> x A}}.	"Ou seja, caso&nbsp;<img src=""paste-61ba1931a33800f7193bafc94667d41fa66142c2.jpg""><br><br>O que implica que&nbsp;<img src=""paste-c6820ad0fc889413c7e03ece5686921eaa57de72.jpg"">"	algebra_linear medium
O eigenvector de uma matriz quadrada é um vetor que, caso seja multiplicado por A, altera apenas a {{c1::escala desse eigenvector}}.	"<img src=""paste-84bccf4caf14824f0137ba86c2b002ac6e2c6c56.jpg"">"	algebra_linear easy
A forma de decomposição de matrizes Singular Value Decomposition (SVD) tem aplicação mais generalizada pois permite que uma {{c1::matriz não quadrada}} seja decomposta.	"<img src=""paste-a6bf819ad841b4780cfa6f363c17023b79bccc07.jpg"">"	algebra_linear easy
O Moore-Penrose Pseudoinverse permite que seja dado mais detalhes para a {{c1::inversa}} de matrizes que {{c1::não são quadradas}}.&nbsp;	"<img src=""paste-471e338188166c7120ee7df21f8599195a8fe45d.jpg"">"	algebra_linear medium
O Trace Operator retorna a {{c1::soma de todos os termos da diagonal de uma matriz}}.	"<img src=""paste-78fcb57fba8b0d4ad4b7373ad250c05782fbc947.jpg"">"	algebra_linear easy
Variável Quantitativa Discreta é composto por números {{c1::naturais}}<br><br>Enquanto a Quantitativa Contínua é composta por números {{c1::decimais}}	Exemplos <b>contínua</b>: horário de entrada, comprimento de uma peça<br><br>Exemplos&nbsp;<b>discreta</b>: número de carteiras em uma sala, número de falhas ou defeitos.	easy estatistica
Variáveis qualitativas podem ser divididas entre {{c1::Nominais}} e {{c1::Ordinais}}.&nbsp;	Ordinais seguem ordem, nominais não seguem<br><br>Exemplos <b>ordinais</b>: escolaridade, classe social<br><br>Exemplos <b>nominais</b>: raça, tipo sanguíneo.	easy estatistica
Qual a função consegue descrever uma distribuição de probabilidade para variáveis discretas?	É a probability mass function (PMF), normalmente denotada com P	easy estatistica
Em estatística, quando se pode dizer que uma distribuição está normatizada?	Quando a somatória de todos os possíveis eventos soma 1.&nbsp;	easy estatistica
Qual função consegue descrever uma distribuição de probabilidade para variáveis contínuas?	É a probability density function (PDF). denotada com p(x).	easy estatistica
"A notação "";"" em estatística significa {{c1::""parametrizado por""}}"		easy estatistica
"<img src=""paste-516132fda9591bdddac23e4e558b0eaccd44961e.jpg"">&nbsp;significa que ""a"" e ""b"" são {{c1::idependentes}}"		easy estatistica
P(a|b) pode ser lido como {{c1::probabilidade de a dado que b ocorra}}		easy estatistica
P(a,b,c) = P(a|b,c)P(b,c) é exemplo de uma {{c1::regra de cadeia da probabilidade}}		easy estatistica
O que é expectativa ou valor esperado (Expectation) de uma função f(x) com respeito a uma distribuição probabilística?	É o valor médio da função quando uma variável aleatória é escolhida da distribuição probabilística.<br><br>Ex: chance de 1 em 10000 de ganhar um prêmio de $5000: Ex[f(x)] = $0,5<br><br>Se eu apostar milhares de vezes, esse é o valor médio que assumiria.	easy estatistica
A notação a~P diz que a variável a {{c1::tem distribuição P}}.		easy estatistica
Probabilidade marginal significa a distribuição de probabilidade para apenas {{c1::um subconjunto de um amaranhado de variáveis}}.		easy estatistica
A variância mede {{c1::o quanto os valores de uma função de uma variável x variam}} de acordo com novas e diferentes valores de x para sua distribuição de probabilidade.	"<img src=""paste-a70706b0eb1966aa6d1d537104db3ab1d19c2d6f.jpg"">"	easy estatistica
A covariância mede {{c1::o quanto duas variáveis são linearmente relacionadas}}, além da {{c1::escala desses valores}}.	"<img src=""paste-ec4aab77d042a631cce8f747acc85e8da4fafbe4.jpg"">"	easy estatistica
<ul><li><b>Covariância com valor absoluto alto</b>: {{c1::variáveis variam muito e estão longe de suas médias}}</li><li><b>Covariância sinal positivo</b>: {{c2::valores altos simultaneamente}}</li><li><b>Covariância sinal negativo</b>: {{c3::uma variável com valor alto e outra com valor pequeno}}<br></li></ul>		easy estatistica
A distribuição de Bernoulli trata apenas de escolhas {{c1::binárias}}	"<img alt=""Distribuições de Dados - Zé Matias"" src=""1nf510NwMhfKhjTxC38yWHA.png"">"	easy estatistica
Quando a variável do experimento toma K saídas, então o sistema pode ser representada por uma distribuição {{c1::Multinoulli}}	"<img alt=""The categorical distribution's algebraic structure"" src=""histogram-of-simonDist.png"">"	easy estatistica
A distribuição probabilistica mais usada para números reais é, normalmente, a {{c1::Distribuição Gaussiana}} ou {{c1::Distribuição Normal}}.	"<img alt=""Lesson Video: Normal Distribution | Nagwa"" src=""thumbnail_l.jpeg"">"	easy estatistica
03fe0fe2b6aa4e0c88e9becbf13d199c-ao-1		"<img src=""tmpaa_9va3e.jpg"">"	"<img src=""03fe0fe2b6aa4e0c88e9becbf13d199c-ao-1-Q.svg"" />"						"<img src=""03fe0fe2b6aa4e0c88e9becbf13d199c-ao-1-A.svg"" />"	"<img src=""03fe0fe2b6aa4e0c88e9becbf13d199c-ao-O.svg"" />"	easy estatistica
"O desvio padrão de uma Distribuição Gaussiana é dada por {{c1::<img src=""paste-0a85369b96dd142063b068673c72800603c854bb.jpg"">}}&nbsp;e a variância por{{c1::&nbsp;<img src=""paste-0a85369b96dd142063b068673c72800603c854bb.jpg""><sup>2</sup>}}."		easy estatistica
O que diz o teorema do limite central, em estatística?	A somatória de várias variáveis aleatórias é aproximadamente uma distribuição normal (Gaussiana).	estatistica medium
No contexto de Deep Learning, sempre procuramos uma distribuição probabilística que tenha uma {{c1::ponta afiada em x = 0}}.		estatistica medium
Qual a equação da função <b>sigmoid</b>?	"<img alt=""Redes neurais - Funções de ativação - Laboratório iMobilis"" src=""paste-ec890e2d690fdb4be9d990b7afe90198d65d4a5d.jpg"">"	easy estatistica
Desenho de uma Logistic sigmoid?	"<img alt=""Sigmoid function - Wikipedia"" src=""1200px-Logistic-curve.svg.png"">"	easy estatistica
Desehno de uma Softplus function?	"<img alt=""The Softplus function (ln(1 + exp(·))) compared to max(0, ·). | Download  Scientific Diagram"" src=""https://www.researchgate.net/profile/Hussam-Lawen/publication/336602359/figure/fig2/AS:814832592908288@1571282637278/The-Softplus-function-ln1-exp-compared-to-max0.ppm"">"	easy estatistica
Qual a equação da função Softplus?	"<img alt=""Different Activation Functions for Deep Neural Networks You Should Know |  by Renu Khandelwal | Geek Culture | Medium"" src=""1invMNMhGkhz2bwvdcoJXPA.png"">"	easy estatistica
Como pode-se obter P(x|y) sabendo o valor de P(y|x)?	"Pode-se usar a regra de Bayes, onde, sabemos P(y|x) e P(x). Assim, computamos P(y) =&nbsp;<img src=""paste-a722658dbf8e2c7c08c5add4f04978ad7aeaf63a.jpg"">&nbsp;P(y|x).P(x) e logo em seguida P(x|y)<br><br><img alt=""Bayes' rule with a simple and practical example | by Tirthajyoti Sarkar |  Towards Data Science"" src=""1CnoTGGO7XeUpUMeXDrIfvA.png"">"	estatistica medium
Como é obtido a self-information do um evento <b>x</b> = x,&nbsp; matemáticamente e teoricamente?	"A teoria de informação dita que um sinal é muito informativo quando a probabilidade dele acontecer é muito baixo (sol nasceu x eclipse) ou quando acontece mais de uma vez (moeda caiu em cara 2x)<br><br>Matemáticamente:&nbsp;<img src=""paste-cf2baf60261871d8a7ac5823eff85ee0dd100da0.jpg"">"	estatistica medium
No que consiste o erro de Underflow?	Esse erro acontece quando é feito um arredondamento de um número próximo de zero para zero. Muitas relação mudam drasticamente com um zero como argumento, alguns ambientes de software também geram excessões para o caso.	computação_numérica easy
Explique o conceito de erro numérico por Overflow.	Overflow acontece quando um número com grande magnitude é tratado como infinito, causando erros.	computação_numérica easy
Como resolver um Underflow ou um Overflow em uma softmax?	Realizando a softmax(z), sendo z=x - max x. Um escalar adicionado a softmax não a altera analíticamente. 	computação_numérica medium
imagens, áudio e textos são tipos de dados {{c1::não estruturados (unstructured data)}}		easy
73ca56ef25c34f07a3c1351fbfe2b36b-ao-1		"<img src=""tmplpqnnb0a.jpg"">"	"<img src=""73ca56ef25c34f07a3c1351fbfe2b36b-ao-1-Q.svg"">"						"<img src=""73ca56ef25c34f07a3c1351fbfe2b36b-ao-1-A.svg"">"	"<img src=""73ca56ef25c34f07a3c1351fbfe2b36b-ao-O.svg"">"	
73ca56ef25c34f07a3c1351fbfe2b36b-ao-2		"<img src=""tmplpqnnb0a.jpg"" />"	"<img src=""73ca56ef25c34f07a3c1351fbfe2b36b-ao-2-Q.svg"" />"						"<img src=""73ca56ef25c34f07a3c1351fbfe2b36b-ao-2-A.svg"" />"	"<img src=""73ca56ef25c34f07a3c1351fbfe2b36b-ao-O.svg"" />"	
Por que uma função linear (Linear Regression) não é indicada para um modelo com distribuição de Bernoulli (classificação binária)?	Uma forma de descobrir y_hat, em ML, é através de uma Linear Regression, o que resultaria em uma equação de parâmetros de reta:<br>y_hat = w^T . x + b<br><br>Porém, isso faz com que a reta resultante apresente valores positivos e maiores que 1, algo que não faz sentido para uma classificação binária.<br><br>Assim, é possível utilizar uma Sigmoid Function para obter um resultado sempre entre zero e um para a distribuição probabilística Bernoulli (Bernoulli Distribution)&nbsp; apresentada (resultados apenas binários).	medium
Logistic Regression é normalmente usada para que tipo de problema de classificação?	"Logistic Regression é um algoritmo de [[Machine Learning]] que pode ser usado para classificação binária. Ele tem como objetivo encontrar qual a probabilidade de uma predição y_hat acontecer dado que uma feature x seja escolhida<br><br><img src=""paste-681542c7b304e70ac1e9fedc4644a3f72ce6abe8.jpg"">"	medium
Qual a relaçao de uma Cost function com uma Loss (error) Function?	"A Cost function nada mais é que uma Loss Function, que é aplicada para um específico exemplo de treinamento com o objetivo de ver a diferença da previsão y_hat do label y, mas aplicada para todo os exemplos. Ou seja, o custo dos seus parâmetros.<br><br><img src=""paste-045964434114e7b14ee1509a20447b427423db88.jpg"">"	medium
Para que é usado um Gradient Descent?	"Gradient Descent é utilizado para convergir a Cost Function a um valor cada vez menor, chegando assim a um optimum.&nbsp;<br><br>Isso é feito a partir da iteração dos parâmetros menos a derivada parcial da Cost function (em relação a w e b) com certo learning rate.&nbsp;<br><br><img src=""paste-9de15354eb2aaa932b4afc03bc295bd43491d828.jpg"">"	easy
a261116876dd4b98abfe25e5eae921e2-ao-1		"<img src=""tmpsbwokz50.jpg"" />"	"<img src=""a261116876dd4b98abfe25e5eae921e2-ao-1-Q.svg"" />"						"<img src=""a261116876dd4b98abfe25e5eae921e2-ao-1-A.svg"" />"	"<img src=""a261116876dd4b98abfe25e5eae921e2-ao-O.svg"">"	medium
Uma matriz jacobiana contém as {{c1::derivadas parciais}} de uma função cujo input e output são {{c1::vetores}}		computação_numérica medium
O que é a estratégia de line search para gradient descent?	A estratégia de line search para gradient descent se baseia em utilizar várias iterações com diferentes learning rates para encontrar a melhor opção.	computação_numérica easy
Uma Hessian matrix pode ser descrita como uma {{c1::Jacobiana do gradiente}}, que normalmente pode ser descrita quando existem {{c1::múltiplos Inputs}}.		computação_numérica easy
Existe uma grande dificuldade para ser escolher um Learning rate. Se ele for muito grande, pode acontecer {{c1::overshooting}}. Se estiver pequena, pode acabar tendo {{c1::pouco progresso}}.<br><br>Esse problema pode ser resolvido com o {{c2::método de Newton}}, que vai utilizar informação de uma {{c2::Hessian Matrix}}.		computação_numérica easy
Algoritmos de otimização de primeira ordem :<br>{{c1::Usam apenas o gradient, como gradient descent}}<br><br>Algoritmos de otimização de segunda ordem:<br>{{c1::Utilizam Hessian Matrix, como método de Newton}}. 		computação_numérica easy
Classification, Regression, Transcription, Machine Learning, etc. São tipos de {{c1::Machine Learning Tasks}}.		computação_numérica easy
Observar uma reapresentação não estruturada de dados para transcrever uma forma textual escrita se trata da task de {{c1::Transcription}}.	Exemplos: Google Street, Speech recognition.	computação_numérica medium
A detection task de identificar fraude em cartões, pelo modelamento de hábitos de compra, é um exemplo de {{c1::Anomaly Detection Task}}.		computação_numérica medium
Gerar um específico output, dado um input , em um problema de texturas de grandes objetos ou paisagens em jogos automaticamente é um exemplo de {{c1::Synthesis e sampling task}}.		medium
Em modelos de classificação, é comum utilizar medidas de performance de {{c1::acurácia}}.	Extra: proporção de exemplos em que o modelo produz a saída correta.	easy
Roughly speaking:<br><br>Unsurpevised Learning se resume em observar um vetor x de exemplos e descobrir implicitamente ou explicitamente a {{c1::distribuição probabilística p(x)}}<br><br>Supervised Learning se resume em observar um vetor x e um vetor de valores associados y e {{c1::prever y dado x, normalmente estimando p(y|x)}}.		easy
Uma forma comum de representar um dataset é por uma {{c1::design matrix, onde exemplos estão em cada linha e features em cada coluna}}. 		easy
Performance de modelo com linear regression, o mais famoso é o {{c1::mean squared errro (MSE)}}		easy
Bias (b) deriva do ponto de vista qua a saída é enviesada a {{c1::assumir o valor de b na ausência de algum input}}.		easy
314914002b5348558410225acb55392e-ao-1		"<img src=""tmpajrda687.jpg"">"	"<img src=""314914002b5348558410225acb55392e-ao-1-Q.svg"">"						"<img src=""314914002b5348558410225acb55392e-ao-1-A.svg"">"	"<img src=""314914002b5348558410225acb55392e-ao-O.svg"">"	medium
314914002b5348558410225acb55392e-ao-2		"<img src=""tmpajrda687.jpg"" />"	"<img src=""314914002b5348558410225acb55392e-ao-2-Q.svg"" />"						"<img src=""314914002b5348558410225acb55392e-ao-2-A.svg"">"	"<img src=""314914002b5348558410225acb55392e-ao-O.svg"" />"	medium
314914002b5348558410225acb55392e-ao-3		"<img src=""tmpajrda687.jpg"" />"	"<img src=""314914002b5348558410225acb55392e-ao-3-Q.svg"" />"						"<img src=""314914002b5348558410225acb55392e-ao-3-A.svg"">"	"<img src=""314914002b5348558410225acb55392e-ao-O.svg"">"	medium
53cfe3dec3974136b79155bbd59cd408-ao-1		"<img src=""tmpjb7xs78b.jpg"">"	"<img src=""53cfe3dec3974136b79155bbd59cd408-ao-1-Q.svg"" />"						"<img src=""53cfe3dec3974136b79155bbd59cd408-ao-1-A.svg"" />"	"<img src=""53cfe3dec3974136b79155bbd59cd408-ao-O.svg"">"	
Criando-se vetores, seria mais indicado qual dos seguintes modelos:<br><ul><li>a =&nbsp; np.random.randn(5)&nbsp;</li></ul><div>OU</div><div><ul><li>a = np.random.randn(5,1)&nbsp;</li></ul></div>	"<i>a = np.random.randn(5,1)&nbsp;</i>é mais indicado, pois força o python a reconhecer como uma matriz 5 por 1, ao contrário do outro comando, que terá valor de a.shape sendo (5, ).&nbsp;<br><br>Isso dificulta ou até impossibilita algumas operações, como a seguir:<br><img src=""paste-d825667eee04a96f532eaa3e1b7506c1ea145af4.jpg"">&nbsp;"	easy
O que faz um neurônio em uma logistic regression?	Calcula uma função linear z = Wx + b seguida de uma função de ativação&nbsp;	easy
1bd5668e2bc742c59063d76d26487d88-ao-1		"<img src=""tmpuk3ip0pv.jpg"">"	"<img src=""1bd5668e2bc742c59063d76d26487d88-ao-1-Q.svg"" />"						"<img src=""1bd5668e2bc742c59063d76d26487d88-ao-1-A.svg"" />"	"<img src=""1bd5668e2bc742c59063d76d26487d88-ao-O.svg"" />"	easy
Uma sigmoid function não tem uma performance muito boa para função de ativação (tanh é melhor na maior parte dos casos), porém uma ocasião que é benéfico se utilizar um sigmoid é para {{c1::o neurônio de saída da rede em casos de classificação. Dessa forma, o resultado estará entre 0 e 1}}.	"<img src=""paste-bde9d81dec7e63e6293f626b3ca7f2e665f3b859.jpg"">"	medium
<ul><li>Em hidden layers, é {{c1::raro}} se ver função de ativação linear</li><li>Em hidden layers, é {{c2::comum}} se ver função de ativação ReLU e tanh.</li></ul>		easy
9d9358773f9d4232ab8d9b6fda3d9ef7-ao-1		"<img src=""tmps0szfk25.jpg"">"	"<img src=""9d9358773f9d4232ab8d9b6fda3d9ef7-ao-1-Q.svg"">"						"<img src=""9d9358773f9d4232ab8d9b6fda3d9ef7-ao-1-A.svg"" />"	"<img src=""9d9358773f9d4232ab8d9b6fda3d9ef7-ao-O.svg"" />"	medium
Por que não é interessante inicializar o parâmetro w com uma matriz de zeros?	Isso não é recomendado pois fará com que os valores das saídas das funções de ativações sejam as mesmas para todos os neurônios. Isso resultará em valores similares para as derivadas na backpropagation, impedindo treinamento da rede.<br><br><i>Each neuron in the first hidden layer will perform the same computation. So even after multiple iterations of gradient descent each neuron in the layer will be computing the same thing as other neurons.&nbsp;</i><br><br>Além disso, não é recomendado ter valores igual por linha e coluna, pois também será gerado semelhança de resultados não desejada.	easy
"<img src=""paste-626bd47779c558f9a08d1822c15845577f78baef.jpg""><br>Por que normalmente se multiplica a inicialização de w por um número pequeno, como 0,01 e não por um número grande como 100?"	"<div style=""text-align: left;"">Isso é feito para que não haja saturação nos valores da função de ativação. Fica claro em um exemplo com tanh:</div><div style=""text-align: center;""><img src=""paste-f6fabdbc8100f706152e2a8e0f6f973ef0761a34.jpg""></div><div style=""text-align: left;""><i>This will cause the inputs of the tanh to also be very large, thus causing gradients to be close to zero. The optimization algorithm will thus become slow.</i><br></div>"	medium
A ativação tanh geralmente funciona melhor do que a função de ativação sigmóide para unidades ocultas porque {{c1::a média de sua saída é mais próxima de zero e, portanto, centraliza os dados melhor para a próxima camada.}}		medium
3ea4b86ba4034de797bb65dcd36a89e3-ao-1		"<img src=""tmptekjki7z.jpg"">"	"<img src=""3ea4b86ba4034de797bb65dcd36a89e3-ao-1-Q.svg"">"				Yes. Sigmoid outputs a value between 0 and 1 which makes it a very good choice for binary classification. You can classify as 0 if the output is less than 0.5 and classify as 1 if the output is more than 0.5. It can be done with tanh as well but it is less convenient as the output is between -1 and 1.		"<img src=""3ea4b86ba4034de797bb65dcd36a89e3-ao-1-A.svg"" />"	"<img src=""3ea4b86ba4034de797bb65dcd36a89e3-ao-O.svg"">"	medium
Para que é usado o k-fold cross-validation algorithm?	É utilizado para estudar erro de generalização de um algoritmo de aprendizado quando o dataset for muito pequeno.	medium
No que se assemelha e no que se difere um modelo de logistic regression e um support vector machine?	- ambos usam uma função linear para computar<br>- SVM, porém, não providência probabilidades como saída, mas sim identidades de classe.	easy
A utilização de kernel em uma support vector machine (SVM) é benefício pois permite {{c1::aprendizado de modelos não lineares}} e {{c2::gera computação mais eficiente que força bruta}}.		medium
k-nearest neighbors é um algoritmo de aprendizagem {{c1::supervisionada}} que pode ser usada tanto para {{c2::classificação como para regressão}}.		easy
É considerado que k-nearest neighbors não possui nenhum parâmetro, mas sim {{c1::uma função dos dados de treinamento}}. Nem se pode falar que há um treinamento em si. Quando queremos produzir um y para um dado x,  achamos {{c2::os k-nearest neighbors para x dentro do dados de treinamento X}}.		medium
Um problema do k-nearest neighbors é que {{c1::não consegue distinguir uma feature que é mais discriminativa que outra}}.	"<img src=""img6383942052815863092.jpg"">"	medium
3ddbac0816804d378ddf8fd2cc8c4a00-ao-1		"<img src=""tmppjnkp_un.jpg"" />"	"<img src=""3ddbac0816804d378ddf8fd2cc8c4a00-ao-1-Q.svg"" />"						"<img src=""3ddbac0816804d378ddf8fd2cc8c4a00-ao-1-A.svg"" />"	"<img src=""3ddbac0816804d378ddf8fd2cc8c4a00-ao-O.svg"" />"	
6bb262d9f05a435096c85faa341c08f9-ao-1		"<img src=""tmpipp47aqy.jpg"" />"	"<img src=""6bb262d9f05a435096c85faa341c08f9-ao-1-Q.svg"" />"						"<img src=""6bb262d9f05a435096c85faa341c08f9-ao-1-A.svg"" />"	"<img src=""6bb262d9f05a435096c85faa341c08f9-ao-O.svg"" />"	
6bb262d9f05a435096c85faa341c08f9-ao-2		"<img src=""tmpipp47aqy.jpg"" />"	"<img src=""6bb262d9f05a435096c85faa341c08f9-ao-2-Q.svg"" />"						"<img src=""6bb262d9f05a435096c85faa341c08f9-ao-2-A.svg"" />"	"<img src=""6bb262d9f05a435096c85faa341c08f9-ao-O.svg"" />"	
1e18fe1b0dcc495badcba9e836511a9f-ao-1		"<img src=""tmp8st389nw.jpg"">"	"<img src=""1e18fe1b0dcc495badcba9e836511a9f-ao-1-Q.svg"" />"				"<img src=""paste-9ceeb6bb2969ae8719f324cfde3999bf1e1c769c.jpg"">"		"<img src=""1e18fe1b0dcc495badcba9e836511a9f-ao-1-A.svg"" />"	"<img src=""1e18fe1b0dcc495badcba9e836511a9f-ao-O.svg"" />"	medium
1f250f60a591496199ba96e48f622742-ao-1		"<img src=""tmpc1dsko57.jpg"" />"	"<img src=""1f250f60a591496199ba96e48f622742-ao-1-Q.svg"" />"						"<img src=""1f250f60a591496199ba96e48f622742-ao-1-A.svg"" />"	"<img src=""1f250f60a591496199ba96e48f622742-ao-O.svg"" />"	medium
Qual o principal problema de realizar uma sub-amostragem diretamente em uma imagem?	Como é feita uma exclusão alternada de coluna e linha, ocorre perda de informações.	easy
O que pode ser realizado antes de uma sub-amostragem para que ocorra menores perdas?	Pode ser realizado uma filtragem, como por exemplo com um filtro gaussiano, para que as informações principais da imagem sejam distribuidas. Assim, perde-se menos informações no processo de sub-amostragem.	easy
Durante a criação de uma rede, é importante ter em mente que a divisão entre train/dev/test estará baseada principalmente {{c1::na quantidade de dados presentes}}&nbsp;e que dev e test sets <b>devem</b> vir da {{c1::mesma distribuição, o que também é interessante para o train set.}}		easy
026f5dcb914d42dfb247a05fcb62770c-ao-1		"<img src=""tmpoxxyfgv3.jpg"" />"	"<img src=""026f5dcb914d42dfb247a05fcb62770c-ao-1-Q.svg"" />"						"<img src=""026f5dcb914d42dfb247a05fcb62770c-ao-1-A.svg"" />"	"<img src=""026f5dcb914d42dfb247a05fcb62770c-ao-O.svg"" />"	
<b>Bias </b>é uma métrica que assume o quanto o modelo faz {{c1::suposições para os dados}}, isso é refletido na {{c1::diferença entre a previsão feita pelo algoritmo com os valores reais esperados}}.<br>&nbsp;&nbsp;&nbsp; - <b>Bias pequeno</b>: {{c1::menas suposições feitas pelo modelo.}}<br>&nbsp;&nbsp;&nbsp; - <b>Bias alto</b>: {{c1::mais suposições feitas pelo modelo --&gt; underfitting}}		medium
<b>Variance </b>é uma métrica que toma em conta a {{c1::mudança dos valores de predição ao se mudar o conjunto de dados de treinamento}}, isso é refletido em {{c1::quanto uma variável aleatória é diferente de seu valor esperado}}.<br>&nbsp;&nbsp;&nbsp; - <b>Variance pequena:</b> {{c1::pequenas variações na previsão com mudanças no training set}}<br>&nbsp;&nbsp;&nbsp; - <b>Variance alta: </b>{{c1::modelo com alta complexidade que reflete muito em variações dos dados --&gt; Overfitting}}		medium
Quando se tem um Bias alto, o que pode ser feito para melhorar o sistema?	Como solução fácil, pode-se:<br><ul><li>Aumentar o número de camadas&nbsp;</li><li>Aumentar o tempo de treinameno</li><li>Procurar uma diferente arquitetura de rede</li><li>Aumentar o número de nodes em cada hidden layer</li></ul>	easy
As principais formas diretas de resolver o problema de variância alta são:	<ul><li>Mais dados</li><li>Regularization</li><li>Pesquisar por uma arquitetura de rede diferente</li><li>Diminuir o número de features (otimizar para ter apenas os que realmente fazem a diferença)</li></ul>	easy
7e4629a15c0346feaaa23efbcb66fcdb-ao-1		"<img src=""tmp92ypg8_x.jpg"" />"	"<img src=""7e4629a15c0346feaaa23efbcb66fcdb-ao-1-Q.svg"" />"						"<img src=""7e4629a15c0346feaaa23efbcb66fcdb-ao-1-A.svg"" />"	"<img src=""7e4629a15c0346feaaa23efbcb66fcdb-ao-O.svg"" />"	easy
Pensando em reduzir overfitting produzido por uma variância alta. Para uma logistic regression, podemos adicionar na cost function uma {{c1::L2 regularization}}. Equanto que em uma rede neural, podemos adicionar uma {{c1::Norma de Frobenius (Praticamente o L2 aplicado para redes neurais)}}.&nbsp;	"Logistic regression:<br><img src=""paste-0df526f3a29b6d36860a4d04d98dc3adf046c7ab.jpg""><br><br>Neural Network:<br><img src=""paste-743260e5f863892b2e587a8882e7a977413a02f0.jpg"">"	easy